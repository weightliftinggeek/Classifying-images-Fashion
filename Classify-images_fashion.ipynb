{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0bb8f6a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Reshape\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import Flatten\n",
    "from keras.constraints import maxnorm\n",
    "from keras.optimizers import SGD, Adam\n",
    "from keras.layers.convolutional import Conv2D\n",
    "from keras.layers.convolutional import MaxPooling2D\n",
    "from keras.utils import np_utils\n",
    "from keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3d0c2b1",
   "metadata": {},
   "source": [
    "### Task 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0dab7dd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Download the data\n",
    "from keras.datasets import fashion_mnist\n",
    "(x_train, y_train), (x_test, y_test) = fashion_mnist.load_data()\n",
    "# reshape dataset to have a single channel\n",
    "x_train = x_train.reshape((x_train.shape[0], 28, 28, 1))\n",
    "x_test = x_test.reshape((x_test.shape[0], 28, 28, 1))\n",
    "\n",
    "#reshape the image dataset into 1 dimension used for NN with no convolutional layers\n",
    "x_train_1d = x_train.reshape((((x_train.shape[0], 28*28))))\n",
    "x_test_1d = x_test.reshape((((x_test.shape[0], 28*28))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "77d61fb3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#reshape y_train and y_test so everything is in 4 dimensions\n",
    "y_train = to_categorical(y_train)\n",
    "y_test = to_categorical(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "8c1ed4c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0.], dtype=float32)"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#test if one-hot encoding worked\n",
    "y_train[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "838c6969",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded fashion_mnist database with 60000 training and 10000 testing samples\n"
     ]
    }
   ],
   "source": [
    "#investigate dataset\n",
    "print('Loaded fashion_mnist database with {} training and {} testing samples'.format(len(y_train), len(y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "07846ab0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 784)"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# investigate input data size\n",
    "x_train.shape\n",
    "x_train_1d.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "014ea363",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 28, 28, 1)"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# investigate test data size\n",
    "x_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "4563aa64",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 10)"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check the dimesions of y\n",
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "14a56ad1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalize inputs from 0-255 to 0.0-1.0\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x_train = x_train / 255.0\n",
    "x_test = x_test / 255.0\n",
    "\n",
    "x_train_1d = x_train_1d.astype('float32')\n",
    "x_test_1d = x_test_1d.astype('float32')\n",
    "x_train_1d = x_train_1d / 255.0\n",
    "x_test_1d = x_test_1d / 255.0\n",
    "\n",
    "# Encode the outputs with one hot coding\n",
    "num_classes = y_test.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5a7cd2f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_6 (Dense)              (None, 10)                7850      \n",
      "=================================================================\n",
      "Total params: 7,850\n",
      "Trainable params: 7,850\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/5\n",
      "60000/60000 [==============================] - 2s 26us/step - loss: 1.0693 - accuracy: 0.6697 - val_loss: 0.8329 - val_accuracy: 0.7216\n",
      "Epoch 2/5\n",
      "60000/60000 [==============================] - 2s 27us/step - loss: 0.7626 - accuracy: 0.7562 - val_loss: 0.7382 - val_accuracy: 0.7603\n",
      "Epoch 3/5\n",
      "60000/60000 [==============================] - 1s 21us/step - loss: 0.6982 - accuracy: 0.7783 - val_loss: 0.6971 - val_accuracy: 0.7719\n",
      "Epoch 4/5\n",
      "60000/60000 [==============================] - 1s 23us/step - loss: 0.6647 - accuracy: 0.7880 - val_loss: 0.6711 - val_accuracy: 0.7809\n",
      "Epoch 5/5\n",
      "60000/60000 [==============================] - 1s 23us/step - loss: 0.6430 - accuracy: 0.7946 - val_loss: 0.6545 - val_accuracy: 0.7874\n",
      "Accuracy: 78.74%\n"
     ]
    }
   ],
   "source": [
    "# Build the model\n",
    "model = Sequential()\n",
    "model.add(Dense(num_classes, activation = 'softmax', input_dim=28*28))\n",
    "#model.add(Dense(num_classes, activation='softmax', input_shape=(28, 28, 1)))\n",
    "\n",
    "# Define optimizer\n",
    "lrate = 0.002\n",
    "epochs = 5\n",
    "decay = lrate/epochs\n",
    "sgd = SGD(lr=lrate, momentum=0.7, decay=decay, nesterov=False) #Stochastic gradient descent optimizer\n",
    "\n",
    "# Compile model\n",
    "model.compile(loss='categorical_crossentropy', optimizer=sgd, metrics=['accuracy'])\n",
    "\n",
    "model.summary()\n",
    "\n",
    "tf.set_random_seed(1)\n",
    "np.random.seed(1)\n",
    "\n",
    "epochs = 5\n",
    "# Fit the model\n",
    "model.fit(x_train_1d, y_train, validation_data=(x_test_1d, y_test), epochs=epochs, batch_size=60, verbose=1)\n",
    "\n",
    "# Final evaluation of the model\n",
    "scores = model.evaluate(x_test_1d, y_test, verbose=0)\n",
    "print(\"Accuracy: %.2f%%\" % (scores[1]*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51737400",
   "metadata": {},
   "source": [
    "Add another dense layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d740d611",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_9\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_11 (Dense)             (None, 20)                15700     \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 10)                210       \n",
      "=================================================================\n",
      "Total params: 15,910\n",
      "Trainable params: 15,910\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/5\n",
      "60000/60000 [==============================] - 2s 26us/step - loss: 1.1436 - accuracy: 0.6308 - val_loss: 0.8082 - val_accuracy: 0.7234\n",
      "Epoch 2/5\n",
      "60000/60000 [==============================] - 2s 40us/step - loss: 0.7274 - accuracy: 0.7587 - val_loss: 0.6971 - val_accuracy: 0.7665\n",
      "Epoch 3/5\n",
      "60000/60000 [==============================] - 1s 23us/step - loss: 0.6529 - accuracy: 0.7862 - val_loss: 0.6501 - val_accuracy: 0.7838\n",
      "Epoch 4/5\n",
      "60000/60000 [==============================] - 2s 27us/step - loss: 0.6143 - accuracy: 0.7993 - val_loss: 0.6209 - val_accuracy: 0.7930\n",
      "Epoch 5/5\n",
      "60000/60000 [==============================] - 1s 24us/step - loss: 0.5895 - accuracy: 0.8062 - val_loss: 0.6039 - val_accuracy: 0.7975\n",
      "Accuracy: 79.75%\n"
     ]
    }
   ],
   "source": [
    "# Build the model\n",
    "model = Sequential()\n",
    "model.add(Dense(20, activation = 'relu', input_dim=28*28))\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "# Define optimizer\n",
    "lrate = 0.002\n",
    "epochs = 5\n",
    "decay = lrate/epochs\n",
    "sgd = SGD(lr=lrate, momentum=0.7, decay=decay, nesterov=False) #Stochastic gradient descent optimizer\n",
    "\n",
    "# Compile model\n",
    "model.compile(loss='categorical_crossentropy', optimizer=sgd, metrics=['accuracy'])\n",
    "\n",
    "model.summary()\n",
    "\n",
    "tf.set_random_seed(1)\n",
    "np.random.seed(1)\n",
    "\n",
    "epochs = 5\n",
    "# Fit the model\n",
    "model.fit(x_train_1d, y_train, validation_data=(x_test_1d, y_test), epochs=epochs, batch_size=60, verbose=1)\n",
    "\n",
    "# Final evaluation of the model\n",
    "scores = model.evaluate(x_test_1d, y_test, verbose=0)\n",
    "print(\"Accuracy: %.2f%%\" % (scores[1]*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4c1b542",
   "metadata": {},
   "source": [
    "### Task 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "0baa5f98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_38\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_12 (Conv2D)           (None, 28, 28, 28)        280       \n",
      "_________________________________________________________________\n",
      "flatten_8 (Flatten)          (None, 21952)             0         \n",
      "_________________________________________________________________\n",
      "dense_40 (Dense)             (None, 10)                219530    \n",
      "=================================================================\n",
      "Total params: 219,810\n",
      "Trainable params: 219,810\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/5\n",
      "60000/60000 [==============================] - 19s 323us/step - loss: 0.7467 - accuracy: 0.7561 - val_loss: 0.5580 - val_accuracy: 0.8033\n",
      "Epoch 2/5\n",
      "60000/60000 [==============================] - 18s 307us/step - loss: 0.5145 - accuracy: 0.8210 - val_loss: 0.5182 - val_accuracy: 0.8187\n",
      "Epoch 3/5\n",
      "60000/60000 [==============================] - 18s 297us/step - loss: 0.4846 - accuracy: 0.8321 - val_loss: 0.4953 - val_accuracy: 0.8238\n",
      "Epoch 4/5\n",
      "60000/60000 [==============================] - 17s 287us/step - loss: 0.4689 - accuracy: 0.8372 - val_loss: 0.4919 - val_accuracy: 0.8233\n",
      "Epoch 5/5\n",
      "60000/60000 [==============================] - 19s 314us/step - loss: 0.4585 - accuracy: 0.8408 - val_loss: 0.4849 - val_accuracy: 0.8285\n",
      "Accuracy: 82.85%\n"
     ]
    }
   ],
   "source": [
    "# Build the model\n",
    "model = Sequential()\n",
    "model.add(Conv2D(28, (3, 3), input_shape=(28, 28, 1), padding='same', activation='relu', kernel_constraint=maxnorm(3)))\n",
    "#model.add(Conv2D(28, (3, 3), activation='relu', padding='same', kernel_constraint=maxnorm(3)))\n",
    "#model.add(MaxPooling2D())\n",
    "model.add(Flatten())\n",
    "#model.add(Dense(512, activation='relu', kernel_constraint=maxnorm(3)))\n",
    "#model.add(Dropout(0.2))\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "# Define optimizer\n",
    "lrate = 0.002\n",
    "epochs = 5\n",
    "decay = lrate/epochs\n",
    "sgd = SGD(lr=lrate, momentum=0.7, decay=decay, nesterov=False) #Stochastic gradient descent optimizer\n",
    "\n",
    "# Compile model\n",
    "model.compile(loss='categorical_crossentropy', optimizer=sgd, metrics=['accuracy'])\n",
    "\n",
    "model.summary()\n",
    "\n",
    "tf.set_random_seed(1)\n",
    "np.random.seed(1)\n",
    "\n",
    "epochs = 5\n",
    "# Fit the model\n",
    "model.fit(x_train, y_train, validation_data=(x_test, y_test), epochs=epochs, batch_size=60, verbose=1)\n",
    "\n",
    "# Final evaluation of the model\n",
    "scores = model.evaluate(x_test, y_test, verbose=0)\n",
    "print(\"Accuracy: %.2f%%\" % (scores[1]*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef8b7ce9",
   "metadata": {},
   "source": [
    "Add a 50% dropout, another convolution layer, maxpooling and a dense layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "de92aa04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_33\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_8 (Conv2D)            (None, 28, 28, 28)        280       \n",
      "_________________________________________________________________\n",
      "conv2d_9 (Conv2D)            (None, 28, 28, 28)        7084      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 14, 14, 28)        0         \n",
      "_________________________________________________________________\n",
      "flatten_6 (Flatten)          (None, 5488)              0         \n",
      "_________________________________________________________________\n",
      "dense_31 (Dense)             (None, 256)               1405184   \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_32 (Dense)             (None, 10)                2570      \n",
      "=================================================================\n",
      "Total params: 1,415,118\n",
      "Trainable params: 1,415,118\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/5\n",
      "60000/60000 [==============================] - 50s 831us/step - loss: 0.8751 - accuracy: 0.6900 - val_loss: 0.5790 - val_accuracy: 0.7925\n",
      "Epoch 2/5\n",
      "60000/60000 [==============================] - 67s 1ms/step - loss: 0.5828 - accuracy: 0.7926 - val_loss: 0.5153 - val_accuracy: 0.8187\n",
      "Epoch 3/5\n",
      "60000/60000 [==============================] - 67s 1ms/step - loss: 0.5261 - accuracy: 0.8141 - val_loss: 0.4715 - val_accuracy: 0.8320\n",
      "Epoch 4/5\n",
      "60000/60000 [==============================] - 73s 1ms/step - loss: 0.4941 - accuracy: 0.8254 - val_loss: 0.4552 - val_accuracy: 0.8368\n",
      "Epoch 5/5\n",
      "60000/60000 [==============================] - 75s 1ms/step - loss: 0.4736 - accuracy: 0.8320 - val_loss: 0.4425 - val_accuracy: 0.8424\n",
      "Accuracy: 84.24%\n"
     ]
    }
   ],
   "source": [
    "# Build the model\n",
    "model = Sequential()\n",
    "model.add(Conv2D(28, (3, 3), input_shape=(28, 28, 1), padding='same', activation='relu', kernel_constraint=maxnorm(3)))\n",
    "model.add(Conv2D(28, (3, 3), activation='relu', padding='same', kernel_constraint=maxnorm(3)))\n",
    "model.add(MaxPooling2D())\n",
    "model.add(Flatten())\n",
    "model.add(Dense(256, activation='relu', kernel_constraint=maxnorm(3)))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "# Define optimizer\n",
    "lrate = 0.002\n",
    "epochs = 5\n",
    "decay = lrate/epochs\n",
    "sgd = SGD(lr=lrate, momentum=0.7, decay=decay, nesterov=False) #Stochastic gradient descent optimizer\n",
    "\n",
    "# Compile model\n",
    "model.compile(loss='categorical_crossentropy', optimizer=sgd, metrics=['accuracy'])\n",
    "\n",
    "model.summary()\n",
    "\n",
    "tf.set_random_seed(1)\n",
    "np.random.seed(1)\n",
    "\n",
    "epochs = 5\n",
    "# Fit the model\n",
    "model.fit(x_train, y_train, validation_data=(x_test, y_test), epochs=epochs, batch_size=60, verbose=1)\n",
    "\n",
    "# Final evaluation of the model\n",
    "scores = model.evaluate(x_test, y_test, verbose=0)\n",
    "print(\"Accuracy: %.2f%%\" % (scores[1]*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50100db2",
   "metadata": {},
   "source": [
    "### Task 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b1978e5",
   "metadata": {},
   "source": [
    "Change the learning rate from 0.002 to 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "bfead537",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_37\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_10 (Conv2D)           (None, 28, 28, 28)        280       \n",
      "_________________________________________________________________\n",
      "conv2d_11 (Conv2D)           (None, 28, 28, 28)        7084      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 14, 14, 28)        0         \n",
      "_________________________________________________________________\n",
      "flatten_7 (Flatten)          (None, 5488)              0         \n",
      "_________________________________________________________________\n",
      "dense_38 (Dense)             (None, 256)               1405184   \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_39 (Dense)             (None, 10)                2570      \n",
      "=================================================================\n",
      "Total params: 1,415,118\n",
      "Trainable params: 1,415,118\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/5\n",
      "60000/60000 [==============================] - 47s 789us/step - loss: 0.5843 - accuracy: 0.7928 - val_loss: 0.4478 - val_accuracy: 0.8361\n",
      "Epoch 2/5\n",
      "60000/60000 [==============================] - 69s 1ms/step - loss: 0.4498 - accuracy: 0.8393 - val_loss: 0.4164 - val_accuracy: 0.8456\n",
      "Epoch 3/5\n",
      "60000/60000 [==============================] - 73s 1ms/step - loss: 0.4228 - accuracy: 0.8487 - val_loss: 0.4013 - val_accuracy: 0.8556\n",
      "Epoch 4/5\n",
      "60000/60000 [==============================] - 73s 1ms/step - loss: 0.4078 - accuracy: 0.8560 - val_loss: 0.3896 - val_accuracy: 0.8565\n",
      "Epoch 5/5\n",
      "60000/60000 [==============================] - 76s 1ms/step - loss: 0.4009 - accuracy: 0.8594 - val_loss: 0.3849 - val_accuracy: 0.8597\n",
      "Accuracy: 85.97%\n"
     ]
    }
   ],
   "source": [
    "# Build the model\n",
    "model = Sequential()\n",
    "model.add(Conv2D(28, (3, 3), input_shape=(28, 28, 1), padding='same', activation='relu', kernel_constraint=maxnorm(3)))\n",
    "model.add(Conv2D(28, (3, 3), activation='relu', padding='same', kernel_constraint=maxnorm(3)))\n",
    "model.add(MaxPooling2D())\n",
    "model.add(Flatten())\n",
    "model.add(Dense(256, activation='relu', kernel_constraint=maxnorm(3)))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "# Define optimizer\n",
    "lrate = 0.5\n",
    "epochs = 5\n",
    "decay = lrate/epochs\n",
    "sgd = SGD(lr=lrate, momentum=0.7, decay=decay, nesterov=False) #Stochastic gradient descent optimizer\n",
    "\n",
    "# Compile model\n",
    "model.compile(loss='categorical_crossentropy', optimizer=sgd, metrics=['accuracy'])\n",
    "\n",
    "model.summary()\n",
    "\n",
    "tf.set_random_seed(1)\n",
    "np.random.seed(1)\n",
    "\n",
    "epochs = 5\n",
    "# Fit the model\n",
    "model.fit(x_train, y_train, validation_data=(x_test, y_test), epochs=epochs, batch_size=60, verbose=1)\n",
    "\n",
    "# Final evaluation of the model\n",
    "scores = model.evaluate(x_test, y_test, verbose=0)\n",
    "print(\"Accuracy: %.2f%%\" % (scores[1]*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "174fb026",
   "metadata": {},
   "source": [
    "Change optimizer from SGD to Adam. However, learning rate of 0.5 did not run well so reduced learning rate to 0.0005"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "e28fa370",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_41\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_17 (Conv2D)           (None, 28, 28, 28)        280       \n",
      "_________________________________________________________________\n",
      "conv2d_18 (Conv2D)           (None, 28, 28, 28)        7084      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_7 (MaxPooling2 (None, 14, 14, 28)        0         \n",
      "_________________________________________________________________\n",
      "flatten_11 (Flatten)         (None, 5488)              0         \n",
      "_________________________________________________________________\n",
      "dense_45 (Dense)             (None, 256)               1405184   \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_46 (Dense)             (None, 10)                2570      \n",
      "=================================================================\n",
      "Total params: 1,415,118\n",
      "Trainable params: 1,415,118\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/5\n",
      "60000/60000 [==============================] - 118s 2ms/step - loss: 0.4760 - accuracy: 0.8318 - val_loss: 0.3205 - val_accuracy: 0.8827\n",
      "Epoch 2/5\n",
      "60000/60000 [==============================] - 98s 2ms/step - loss: 0.3095 - accuracy: 0.8893 - val_loss: 0.2771 - val_accuracy: 0.8974\n",
      "Epoch 3/5\n",
      "60000/60000 [==============================] - 114s 2ms/step - loss: 0.2688 - accuracy: 0.9026 - val_loss: 0.2606 - val_accuracy: 0.9057\n",
      "Epoch 4/5\n",
      "60000/60000 [==============================] - 123s 2ms/step - loss: 0.2352 - accuracy: 0.9140 - val_loss: 0.2381 - val_accuracy: 0.9120\n",
      "Epoch 5/5\n",
      "60000/60000 [==============================] - 103s 2ms/step - loss: 0.2130 - accuracy: 0.9207 - val_loss: 0.2279 - val_accuracy: 0.9183\n",
      "Accuracy: 91.83%\n"
     ]
    }
   ],
   "source": [
    "# Build the model\n",
    "model = Sequential()\n",
    "model.add(Conv2D(28, (3, 3), input_shape=(28, 28, 1), padding='same', activation='relu', kernel_constraint=maxnorm(3)))\n",
    "model.add(Conv2D(28, (3, 3), activation='relu', padding='same', kernel_constraint=maxnorm(3)))\n",
    "model.add(MaxPooling2D())\n",
    "model.add(Flatten())\n",
    "model.add(Dense(256, activation='relu', kernel_constraint=maxnorm(3)))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "# Define optimizer\n",
    "lrate = 0.0005\n",
    "adam = Adam(learning_rate=lrate) #Adam optimizer\n",
    "\n",
    "# Compile model\n",
    "model.compile(loss='categorical_crossentropy', optimizer=adam, metrics=['accuracy'])\n",
    "\n",
    "model.summary()\n",
    "\n",
    "tf.set_random_seed(1)\n",
    "np.random.seed(1)\n",
    "\n",
    "epochs = 5\n",
    "# Fit the model\n",
    "model.fit(x_train, y_train, validation_data=(x_test, y_test), epochs=epochs, batch_size=60, verbose=1)\n",
    "\n",
    "# Final evaluation of the model\n",
    "scores = model.evaluate(x_test, y_test, verbose=0)\n",
    "print(\"Accuracy: %.2f%%\" % (scores[1]*100))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
